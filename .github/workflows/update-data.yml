name: Daily Investment Calendar Update

on:
  schedule:
    # 每天北京时间 6:00 (UTC 22:00) 执行
    - cron: '0 22 * * *'
  workflow_dispatch: # 允许手动触发

permissions:
  contents: write

jobs:
  update-data:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -r scripts/requirements.txt
    
    - name: Ensure directory structure
      run: |
        mkdir -p data/web
        mkdir -p data/active/current
        mkdir -p data/active/previous
        echo "📁 当前目录结构："
        ls -la
        echo "📁 Data目录结构："
        ls -la data/ || echo "Data目录不存在"
        echo "📁 Archived目录结构："
        ls -la data/archived/ || echo "Archived目录不存在"
    
    - name: Check current data status
      id: check_data
      run: |
        echo "🔍 检查当前数据状态..."
        
        current_count=0
        for platform in cls jiuyangongshe tonghuashun investing eastmoney; do
          file_path="data/active/current/${platform}.txt"
          if [ -f "$file_path" ] && [ -s "$file_path" ]; then
            current_count=$((current_count + 1))
            echo "✅ 发现 ${platform}.txt ($(stat -c%s "$file_path") bytes)"
          else
            echo "❌ 缺少或为空: ${platform}.txt"
          fi
        done
        
        echo "📊 当前数据文件: $current_count/5"
        
        if [ $current_count -ge 3 ]; then
          echo "run_mode=daily" >> $GITHUB_OUTPUT
          echo "🔄 使用日常更新模式"
        else
          echo "run_mode=first-run" >> $GITHUB_OUTPUT
          echo "🚀 使用首次运行模式"
        fi
    
    - name: Run investment calendar
      run: |
        mode="${{ steps.check_data.outputs.run_mode }}"
        echo "🚀 执行模式: $mode"
        
        if [ "$mode" == "daily" ]; then
          python scripts/daily_calendar.py --daily
        else
          if [ ! -f "data/archived/historical_summary.txt" ]; then
            echo "📚 开始采集历史数据..."
            python scripts/historical_collector.py
          fi
          echo "🚀 开始首次运行..."
          python scripts/daily_calendar.py --first-run
        fi
        
        # 检查数据采集结果
        echo "📊 数据采集后的current目录:"
        ls -la data/active/current/ || echo "Current目录不存在"
        
        echo "📄 Current目录文件大小:"
        du -h data/active/current/*.txt 2>/dev/null || echo "无txt文件"
    
    - name: Create comprehensive data converter script
      run: |
        cat > convert_data.py << 'EOF'
        import json
        import os
        import glob
        from datetime import datetime

        def convert_platform_data(platform):
            source_file = f'data/active/current/{platform}.txt'
            target_file = f'data/web/{platform}.json'
            
            if not os.path.exists(source_file):
                print(f'⚠️ {platform} 源文件不存在')
                return False
            
            try:
                with open(source_file, 'r', encoding='utf-8') as f:
                    data = json.loads(f.read())
                
                platform_names = {
                    'cls': '财联社',
                    'jiuyangongshe': '韭研公社', 
                    'tonghuashun': '同花顺',
                    'investing': '英为财情',
                    'eastmoney': '东方财富'
                }
                
                web_data = {
                    'platform': platform,
                    'platform_name': platform_names.get(platform, platform),
                    'data_type': 'ACTIVE',
                    'total_events': data.get('total_events', 0),
                    'last_updated': data.get('last_updated', datetime.now().isoformat()),
                    'events': []
                }
                
                for event_data in data.get('events', []):
                    web_event = {
                        'id': event_data.get('event_id', ''),
                        'platform': event_data.get('platform', ''),
                        'title': event_data.get('title', ''),
                        'event_date': event_data.get('event_date', ''),
                        'event_time': event_data.get('event_time'),
                        'event_datetime': event_data.get('event_datetime'),
                        'content': event_data.get('content'),
                        'category': event_data.get('category'),
                        'importance': event_data.get('importance', 1),
                        'country': event_data.get('country'),
                        'city': event_data.get('city'),
                        'is_new': event_data.get('is_new', False),
                        'discovery_date': event_data.get('discovery_date'),
                        'data_status': event_data.get('data_status', 'ACTIVE'),
                        'stocks': event_data.get('stocks', []),
                        'themes': event_data.get('themes', []),
                        'concepts': event_data.get('concepts', [])
                    }
                    web_data['events'].append({k: v for k, v in web_event.items() if v is not None})
                
                with open(target_file, 'w', encoding='utf-8') as f:
                    json.dump(web_data, f, ensure_ascii=False, indent=2)
                
                print(f'✅ {platform} 转换完成: {len(web_data["events"])} 个事件')
                return True
                
            except Exception as e:
                print(f'❌ {platform} 转换失败: {e}')
                return False

        def convert_archived_data():
            print("📚 开始转换历史归档数据...")
            
            archived_path = "data/archived"
            if not os.path.exists(archived_path):
                print("⚠️ 归档目录不存在")
                return 0
            
            platform_names = {
                'cls': '财联社',
                'jiuyangongshe': '韭研公社', 
                'tonghuashun': '同花顺',
                'investing': '英为财情',
                'eastmoney': '东方财富'
            }
            
            platforms = ['cls', 'jiuyangongshe', 'tonghuashun', 'investing', 'eastmoney']
            converted_files = 0
            
            for year_dir in os.listdir(archived_path):
                if not year_dir.isdigit():
                    continue
                    
                year_path = os.path.join(archived_path, year_dir)
                if not os.path.isdir(year_path):
                    continue
                
                print(f"📅 处理 {year_dir} 年数据...")
                
                for month_dir in os.listdir(year_path):
                    if not month_dir.endswith('月'):
                        continue
                        
                    month_path = os.path.join(year_path, month_dir)
                    if not os.path.isdir(month_path):
                        continue
                    
                    month_num = month_dir.replace('月', '').zfill(2)
                    print(f"  📊 处理 {year_dir}-{month_num} 数据...")
                    
                    for platform in platforms:
                        source_file = os.path.join(month_path, f"{platform}.txt")
                        if not os.path.exists(source_file):
                            continue
                        
                        try:
                            with open(source_file, 'r', encoding='utf-8') as f:
                                data = json.loads(f.read())
                            
                            target_file = f"data/web/{platform}_history_{year_dir}_{month_num}.json"
                            
                            web_data = {
                                'platform': platform,
                                'platform_name': platform_names.get(platform, platform),
                                'data_type': 'HISTORICAL',
                                'year': int(year_dir),
                                'month': int(month_num),
                                'total_events': data.get('total_events', 0),
                                'events': []
                            }
                            
                            for event_data in data.get('events', []):
                                web_event = {
                                    'id': event_data.get('event_id', ''),
                                    'platform': event_data.get('platform', ''),
                                    'title': event_data.get('title', ''),
                                    'event_date': event_data.get('event_date', ''),
                                    'event_time': event_data.get('event_time'),
                                    'content': event_data.get('content'),
                                    'category': event_data.get('category'),
                                    'importance': event_data.get('importance', 1),
                                    'country': event_data.get('country'),
                                    'city': event_data.get('city'),
                                    'data_status': 'ARCHIVED',
                                    'stocks': event_data.get('stocks', []),
                                    'themes': event_data.get('themes', []),
                                    'concepts': event_data.get('concepts', [])
                                }
                                web_data['events'].append({k: v for k, v in web_event.items() if v is not None})
                            
                            with open(target_file, 'w', encoding='utf-8') as f:
                                json.dump(web_data, f, ensure_ascii=False, indent=2)
                            
                            converted_files += 1
                            print(f"    ✅ {platform} {year_dir}-{month_num}: {len(web_data['events'])} 个事件")
                            
                        except Exception as e:
                            print(f"    ❌ {platform} {year_dir}-{month_num} 转换失败: {e}")
            
            print(f"📚 历史数据转换完成，共转换 {converted_files} 个文件")
            return converted_files

        def generate_historical_index():
            print("📋 生成历史数据索引...")
            
            historical_files = glob.glob("data/web/*_history_*.json")
            
            index = {
                'generated_at': datetime.now().isoformat(),
                'total_files': len(historical_files),
                'available_periods': [],
                'platforms': {}
            }
            
            periods = set()
            platform_data = {}
            
            for file_path in historical_files:
                try:
                    filename = os.path.basename(file_path)
                    parts = filename.replace('.json', '').split('_')
                    if len(parts) >= 4:
                        platform = parts[0]
                        year = parts[2]
                        month = parts[3]
                        period = f"{year}-{month}"
                        
                        periods.add(period)
                        
                        if platform not in platform_data:
                            platform_data[platform] = []
                        platform_data[platform].append(period)
                        
                except Exception as e:
                    print(f"解析文件名失败: {filename}, {e}")
            
            index['available_periods'] = sorted(list(periods))
            index['platforms'] = {k: sorted(v) for k, v in platform_data.items()}
            
            with open('data/web/historical_index.json', 'w', encoding='utf-8') as f:
                json.dump(index, f, ensure_ascii=False, indent=2)
            
            print(f"📋 历史索引生成完成: {len(periods)} 个时期，{len(platform_data)} 个平台")

        def convert_change_reports():
            print("📊 转换变更报告...")
            
            platform_names = {
                'cls': '财联社',
                'jiuyangongshe': '韭研公社', 
                'tonghuashun': '同花顺',
                'investing': '英为财情',
                'eastmoney': '东方财富'
            }
            
            change_files = glob.glob('data/active/current/change_report_*.txt')
            for change_file in change_files:
                try:
                    with open(change_file, 'r', encoding='utf-8') as f:
                        change_data = json.loads(f.read())
                    
                    web_change_data = {
                        'detection_time': change_data.get('detection_time'),
                        'summary': change_data.get('summary', {}),
                        'platforms': {},
                        'top_new_events': []
                    }
                    
                    for platform, changes in change_data.get('platforms', {}).items():
                        web_change_data['platforms'][platform] = {
                            'name': platform_names.get(platform, platform),
                            'new_events': changes.get('new_events', 0),
                            'updated_events': changes.get('updated_events', 0),
                            'cancelled_events': changes.get('cancelled_events', 0),
                            'sample_new_titles': changes.get('sample_new_titles', [])
                        }
                    
                    for event in change_data.get('top_new_events', []):
                        web_event = {
                            'platform': event.get('platform'),
                            'platform_name': platform_names.get(event.get('platform', ''), event.get('platform', '')),
                            'date': event.get('date'),
                            'title': event.get('title'),
                            'importance': event.get('importance'),
                            'country': event.get('country')
                        }
                        web_change_data['top_new_events'].append(web_event)
                    
                    change_filename = os.path.basename(change_file).replace('.txt', '.json')
                    with open(f'data/web/{change_filename}', 'w', encoding='utf-8') as f:
                        json.dump(web_change_data, f, ensure_ascii=False, indent=2)
                    
                    print(f'✅ 变更报告转换完成: {change_filename}')
                    
                except Exception as e:
                    print(f'❌ 变更报告转换失败: {e}')

        def main():
            print("🔄 开始数据转换...")
            
            platforms = ['cls', 'jiuyangongshe', 'tonghuashun', 'investing', 'eastmoney']
            current_converted = 0
            
            print("📊 转换当前数据...")
            for platform in platforms:
                if convert_platform_data(platform):
                    current_converted += 1
            
            historical_converted = convert_archived_data()
            generate_historical_index()
            convert_change_reports()
            
            print("📋 生成元数据...")
            metadata = {
                'last_updated': datetime.now().isoformat(),
                'total_events': 0,
                'platforms': {},
                'has_historical_data': historical_converted > 0,
                'historical_files': historical_converted
            }
            
            platform_names = {
                'cls': '财联社',
                'jiuyangongshe': '韭研公社', 
                'tonghuashun': '同花顺',
                'investing': '英为财情',
                'eastmoney': '东方财富'
            }
            
            for platform in platforms:
                json_file = f'data/web/{platform}.json'
                if os.path.exists(json_file):
                    try:
                        with open(json_file, 'r', encoding='utf-8') as f:
                            data = json.loads(f.read())
                            event_count = data.get('total_events', 0)
                            metadata['total_events'] += event_count
                            metadata['platforms'][platform] = {
                                'name': data.get('platform_name', platform),
                                'event_count': event_count
                            }
                    except Exception as e:
                        print(f'读取{platform}元数据失败: {e}')
            
            with open('data/web/metadata.json', 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f'🎉 转换完成!')
            print(f'当前数据: {current_converted} 个平台')
            print(f'历史数据: {historical_converted} 个文件')
            print(f'总事件数: {metadata["total_events"]}')

        if __name__ == '__main__':
            main()
        EOF
    
    - name: Convert data for web
      run: |
        echo "🔄 转换数据为Web格式..."
        mkdir -p data/web
        python3 convert_data.py
        
        echo "📊 Web数据生成结果:"
        ls -la data/web/ || echo "Web目录不存在"
        
        echo "📄 生成的JSON文件统计:"
        current_files=$(ls data/web/*.json 2>/dev/null | grep -v history | grep -v index | grep -v metadata | grep -v change_report | wc -l)
        history_files=$(ls data/web/*_history_*.json 2>/dev/null | wc -l)
        other_files=$(ls data/web/*index*.json data/web/metadata.json data/web/change_report*.json 2>/dev/null | wc -l)
        
        echo "  - 当前数据: $current_files 个"
        echo "  - 历史数据: $history_files 个"
        echo "  - 其他文件: $other_files 个"
        
        echo "📋 历史数据文件示例:"
        ls data/web/*_history_*.json 2>/dev/null | head -5 || echo "无历史数据文件"
    
    - name: Configure Git
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
    
    - name: Commit and push changes
      run: |
        echo "📝 准备提交更改..."
        
        echo "📊 Current目录内容:"
        ls -la data/active/current/ || echo "Current目录不存在"
        
        git add data/active/current/*.txt 2>/dev/null || echo "无current数据文件"
        git add data/web/ || echo "无web数据"
        git add data/active/current/metadata.txt 2>/dev/null || echo "无元数据文件"
        
        if [ -n "$(git status --porcelain)" ]; then
          echo "📊 发现以下变更:"
          git status --porcelain | head -20
          
          total_changes=$(git status --porcelain | wc -l)
          if [ $total_changes -gt 20 ]; then
            echo "... 还有 $((total_changes - 20)) 个变更文件"
          fi
          
          git commit -m "📊 Daily data update - $(date +'%Y-%m-%d %H:%M:%S')"
          git push
          echo "✅ 变更已提交并推送"
        else
          echo "ℹ️ 没有需要提交的变更"
        fi
    
    - name: Deployment summary
      run: |
        echo "🎉 数据更新完成!"
        echo "📊 最终状态:"
        echo "  - 运行模式: ${{ steps.check_data.outputs.run_mode }}"
        
        current_count=$(ls data/active/current/*.txt 2>/dev/null | wc -l)
        web_count=$(ls data/web/*.json 2>/dev/null | wc -l)
        history_count=$(ls data/web/*_history_*.json 2>/dev/null | wc -l)
        
        echo "  - Current数据: $current_count 个文件"
        echo "  - Web数据: $web_count 个JSON文件"
        echo "  - 历史数据: $history_count 个历史文件"
        echo "  - 网站地址: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/"
        
        if [ -f "data/web/metadata.json" ]; then
          echo "📈 数据统计:"
          python3 -c "
import json
try:
    with open('data/web/metadata.json', 'r') as f:
        metadata = json.load(f)
    print('  - 总事件数: ' + str(metadata.get('total_events', 0)))
    print('  - 活跃平台: ' + str(len(metadata.get('platforms', {}))))
    print('  - 历史文件: ' + str(metadata.get('historical_files', 0)))
    print('  - 最后更新: ' + metadata.get('last_updated', '未知'))
except Exception as e:
    print('  - 无法读取元数据: ' + str(e))
"
        fi
        
        if [ -f "data/web/historical_index.json" ]; then
          echo "📅 历史数据索引:"
          python3 -c "
import json
try:
    with open('data/web/historical_index.json', 'r') as f:
        index = json.load(f)
    periods = index.get('available_periods', [])
    print('  - 可用时期: ' + str(len(periods)) + ' 个')
    if periods:
        print('  - 时间范围: ' + periods[0] + ' 至 ' + periods[-1])
        recent = periods[-3:] if len(periods) >= 3 else periods
        print('  - 最新时期: ' + str(recent))
except Exception as e:
    print('  - 无法读取历史索引: ' + str(e))
"
        fi
        
        echo ""
        echo "🌐 访问网站查看数据更新结果！"
